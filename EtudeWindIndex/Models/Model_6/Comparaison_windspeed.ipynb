{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c2b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xarray in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.16.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xarray) (1.1.5)\n",
      "Requirement already satisfied: setuptools>=38.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xarray) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xarray) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.25->xarray) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.25->xarray) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas>=0.25->xarray) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d625d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.2)\n",
      "Requirement already satisfied: sqlalchemy-redshift in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.8.9)\n",
      "Requirement already satisfied: pykeepass in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.0,>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sqlalchemy-redshift) (1.4.31)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sqlalchemy-redshift) (21.3)\n",
      "Requirement already satisfied: construct==2.10.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (2.10.54)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (2.8.1)\n",
      "Requirement already satisfied: argon2-cffi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (20.1.0)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (4.6.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (3.14.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pykeepass) (0.18.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from SQLAlchemy<2.0.0,>=0.9.2->sqlalchemy-redshift) (3.7.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from SQLAlchemy<2.0.0,>=0.9.2->sqlalchemy-redshift) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from argon2-cffi->pykeepass) (1.14.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from argon2-cffi->pykeepass) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->sqlalchemy-redshift) (2.4.7)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi>=1.0.0->argon2-cffi->pykeepass) (2.20)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->SQLAlchemy<2.0.0,>=0.9.2->sqlalchemy-redshift) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->SQLAlchemy<2.0.0,>=0.9.2->sqlalchemy-redshift) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql sqlalchemy-redshift pykeepass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8159ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.7.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60a574bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 28.6 MB/s            \n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b04533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import xarray as xr #to read netcdf\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pathlib import Path\n",
    "from pykeepass import PyKeePass\n",
    "import getpass\n",
    "from datetime import datetime\n",
    "import sqlalchemy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import boto3 #Save in S3\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e5dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logger set-up\n",
    "logging.basicConfig(format=' %(asctime)s -  %(levelname)s -  %(message)s', \n",
    "                    handlers = [logging.StreamHandler()])\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c827402",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_bucket_name = 'edfred-edfre-sbx-eu-west-1-solar-radiation-data'\n",
    "S3_CSV_FOLD_ERA5 = r'EtudeWindIndex/ERA5'\n",
    "S3_CSV_FOLD_DATA = r'EtudeWindIndex/Real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a8042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2022-01-31 12:46:38,532 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 12:46:38,533 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 12:46:38,538 -  INFO -  We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      " 2022-01-31 12:46:38,539 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 12:46:38,546 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 12:46:38,547 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 12:46:38,551 -  INFO -  We detected language [('German', 0.8333), ('Hungarian', 0.8333), ('Slovak', 0.8333), ('English', 0.75), ('Dutch', 0.75), ('Italian', 0.75), ('Swedish', 0.75), ('Norwegian', 0.75), ('Czech', 0.75), ('Indonesian', 0.75), ('Danish', 0.75), ('Polish', 0.6667), ('Finnish', 0.6667), ('Slovene', 0.6667), ('Turkish', 0.5833), ('Vietnamese', 0.5), ('Lithuanian', 0.5)] using ascii\n",
      " 2022-01-31 12:46:38,551 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 12:46:38,563 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 12:46:38,563 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 12:46:38,568 -  INFO -  We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      " 2022-01-31 12:46:38,568 -  INFO -  ascii is most likely the one. Stopping the process.\n"
     ]
    }
   ],
   "source": [
    "# read project information and compute associated nodes\n",
    "S3_project_url = f's3://{S3_bucket_name}/ERA5/config/ERA5_project_list.csv'\n",
    "projects = pd.read_csv(S3_project_url, index_col='project_code', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806df8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUQB</th>\n",
       "      <td>43.60</td>\n",
       "      <td>3.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEL</th>\n",
       "      <td>48.83</td>\n",
       "      <td>6.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOUS</th>\n",
       "      <td>49.19</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRIY</th>\n",
       "      <td>49.75</td>\n",
       "      <td>3.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIT</th>\n",
       "      <td>49.66</td>\n",
       "      <td>-1.370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              latitude  longitude\n",
       "project_code                     \n",
       "AUQB             43.60      3.622\n",
       "AMEL             48.83      6.460\n",
       "BOUS             49.19      6.520\n",
       "BRIY             49.75      3.400\n",
       "CLIT             49.66     -1.370"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b459ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On choisit la période\n",
    "start_month = '2000-01'\n",
    "end_month = '2021-11'\n",
    "\n",
    "List_projects = ['CDBO','AMEL','ESPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a724d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère la courbe de puissance\n",
    "S3_pc_url = f's3://{S3_bucket_name}/ERA5/config/power_curve_V90-3.0MW.csv'\n",
    "power_curve = pd.read_csv(S3_pc_url, index_col='windspeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a1655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2022-01-31 14:59:40,118 -  INFO -  project : CDBO\n",
      " 2022-01-31 15:02:29,451 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 15:02:29,452 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 15:02:29,454 -  INFO -  We detected language [('Indonesian', 1.0), ('Simple English', 1.0), ('English', 0.9524)] using ascii\n",
      " 2022-01-31 15:02:29,457 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 15:02:29,463 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 15:02:29,464 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 15:02:29,464 -  INFO -  We detected language [('German', 0.8333), ('Hungarian', 0.8333), ('Slovak', 0.8333), ('English', 0.75), ('Dutch', 0.75), ('Italian', 0.75), ('Swedish', 0.75), ('Norwegian', 0.75), ('Czech', 0.75), ('Indonesian', 0.75), ('Danish', 0.75), ('Polish', 0.6667), ('Finnish', 0.6667), ('Slovene', 0.6667), ('Turkish', 0.5833), ('Vietnamese', 0.5), ('Lithuanian', 0.5)] using ascii\n",
      " 2022-01-31 15:02:29,465 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 15:02:29,477 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 15:02:29,478 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 15:02:29,480 -  INFO -  We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      " 2022-01-31 15:02:29,481 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 15:02:33,479 -  INFO -  Complété à : 33.33333333333333%\n",
      " 2022-01-31 15:02:33,480 -  INFO -  project : AMEL\n",
      " 2022-01-31 15:05:29,369 -  INFO -  Complété à : 66.66666666666666%\n",
      " 2022-01-31 15:05:29,370 -  INFO -  project : ESPS\n"
     ]
    }
   ],
   "source": [
    "months_range = pd.date_range(start=start_month, end=end_month, freq='MS')\n",
    "\n",
    "for code in projects.loc[List_projects].index :\n",
    "    \n",
    "    logging.info(\"project : {}\".format(code))\n",
    "    \n",
    "    projects_ERA5 = pd.DataFrame(columns=['time','u100','v100','u10','v10','d2m','t2m','sf','sp','msdwswrf','tp'])\n",
    "    projects_ERA5.set_index('time',inplace=True)\n",
    "\n",
    "    for date in months_range :\n",
    "        #Construction des chemins vers les données\n",
    "        input_name_nc = f'ERA5_france_'+str(date)[0:7]+'.nc'\n",
    "        bucket_name = 'edfred-edfre-sbx-eu-west-1-solar-radiation-data'\n",
    "        S3_origin = os.path.join('ERA5', 'netcdf', 'france', input_name_nc)  \n",
    "        body = boto3.Session().resource('s3').Bucket(bucket_name).Object(S3_origin).get()['Body'].read()\n",
    "        netcdf = xr.open_dataset(body, )\n",
    "        #Récupération des données\n",
    "        df_ERA5 = netcdf.sel(latitude=projects.loc[code].latitude, longitude=projects.loc[code].latitude, method=\"nearest\").to_dataframe()\n",
    "        df_ERA5.drop(columns=['longitude', 'latitude'], inplace=True)\n",
    "        \n",
    "        projects_ERA5 = pd.concat([projects_ERA5, df_ERA5])\n",
    "    \n",
    "    #On calcule les vitesses et direction de vent\n",
    "    projects_ERA5['ws100'] = (projects_ERA5['u100']**2 + projects_ERA5['v100']**2)**0.5\n",
    "    projects_ERA5['wd100'] = round(np.arctan2(projects_ERA5['u100'], projects_ERA5['v100'])*180/pi + 180,0)\n",
    "    projects_ERA5['ws10'] = (projects_ERA5['u10']**2 + projects_ERA5['v10']**2)**0.5\n",
    "    projects_ERA5['wd10'] = round(np.arctan2(projects_ERA5['u10'], projects_ERA5['v10'])*180/pi + 180,0)\n",
    "    projects_ERA5['E100'] = np.interp(projects_ERA5['ws100'], power_curve.index, power_curve['power'])  # Energy (using a power curve)\n",
    "    projects_ERA5['rh'] = 100 - 5 * (projects_ERA5['t2m'] - projects_ERA5['d2m'])\n",
    "    projects_ERA5['density'] = projects_ERA5['sp'] /  ( 287.058 * projects_ERA5['t2m'])\n",
    "    projects_ERA5['E100_cor'] = projects_ERA5['E100']*projects_ERA5['density']/1.225   \n",
    "    \n",
    "    #On enlève les colonnes en trop\n",
    "    projects_ERA5.drop(columns=['u100', 'v100'], inplace=True)\n",
    "    projects_ERA5.drop(columns=['u10', 'v10'], inplace=True)\n",
    "    projects_ERA5.drop(columns=['sf', 'msdwswrf', 'tp'], inplace=True)\n",
    "    \n",
    "    #Sauvegarde \n",
    "    ERA5_hourly_path = Path('/home/ec2-user/SageMaker/EtudeWindIndex/Data/ERA5/ERA5_hourly/Clean/ERA5_'+code+'.csv')\n",
    "    projects_ERA5.to_csv(ERA5_hourly_path, index=True, sep=';')\n",
    "    \n",
    "    #Sauvegarde sur le S3\n",
    "    outfile = 'ERA5_'+code+'.csv'\n",
    "    projects_ERA5.to_csv(f's3://{S3_bucket_name}/{S3_CSV_FOLD_ERA5}/{outfile}', index=True, sep=';')\n",
    "    \n",
    "    logging.info(\"Complété à : \"+str((List_projects.index(code)+1)/len(List_projects)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e93370",
   "metadata": {},
   "source": [
    "# Accès aux données Keepass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d2383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide password to get acces to Keepass file:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ·········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2022-01-31 12:47:05,280 -  INFO -  Keepass data loaded\n"
     ]
    }
   ],
   "source": [
    "#Get logging information stored in keepass\n",
    "Configuration_path = Path('/home/ec2-user/SageMaker/EtudeWindIndex/Data/Windga/WindGa_hourly/Configuration')\n",
    "KEEPASS_FILE = Configuration_path/'RDL.kdbx'\n",
    "\n",
    "logging.basicConfig(format=' %(asctime)s -  %(levelname)s -  %(message)s', handlers = [logging.StreamHandler()])\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print('Provide password to get acces to Keepass file:')\n",
    "password = getpass.getpass()\n",
    "\n",
    "try:  \n",
    "    kp = PyKeePass(KEEPASS_FILE, password=password)\n",
    "    logging.info('Keepass data loaded')\n",
    "except:\n",
    "    logging.exception('Cannot open the keepass file:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c28bf",
   "metadata": {},
   "source": [
    "# Connection à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d77bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connexion_setup(kp_con_name='SBX-RDS'):\n",
    "\n",
    "    credential = kp.find_entries(title=kp_con_name, first=True)\n",
    "\n",
    "    con = credential.url.split('//')[0] + '//' + \\\n",
    "    credential.username +':'+ \\\n",
    "    credential.password + \\\n",
    "    credential.url.split('//')[1]\n",
    "    logging.debug(f'connexion string: {con}')\n",
    "\n",
    "    con_engine = sqlalchemy.create_engine(con)\n",
    "\n",
    "    return con_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55348079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read mapping file\n",
    "VAR_MAPPING_FILE = Configuration_path/'10min_variables_iec_to_std_names_mapping.csv'\n",
    "df = pd.read_csv(VAR_MAPPING_FILE)\n",
    "\n",
    "#Mapping dict\n",
    "iec2std = df.loc[:,['iec_attribute61400','business_description']].set_index('iec_attribute61400')['business_description'].to_dict()\n",
    "std2iec = df.loc[:,['iec_attribute61400','business_description']].set_index('business_description')['iec_attribute61400'].to_dict()\n",
    "\n",
    "#Récupération des données utiles\n",
    "mask_features = [False]\n",
    "List_features = ['active_power_avg','wind_speed_avg']\n",
    "for feature in List_features :\n",
    "    mask_features = mask_features | (df.business_description == feature)\n",
    "temperature_features = df.loc[mask_features,:]\n",
    "features_selection_str = str(list(temperature_features.iec_attribute61400)).replace(\"'\", '').replace(\"[\", \"\").replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bf91f",
   "metadata": {},
   "source": [
    "# Extraction de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411f82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Periode à extraire\n",
    "start_month = '2020-01'\n",
    "end_month = '2021-11'\n",
    "\n",
    "months_range = pd.date_range(start=start_month, end=end_month, freq='MS')\n",
    "months_list = [str(months_range[i])[0:7] for i in range(len(months_range))]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72b4246d",
   "metadata": {},
   "source": [
    "for PROJECT in List_projects :\n",
    "    \n",
    "    logging.info(\"project : {}\".format(PROJECT))\n",
    "    \n",
    "    _10min_project = pd.DataFrame(columns=['asset_id','ts'] + List_features)\n",
    "    \n",
    "    #Number of WTGS in this project from WDM\n",
    "    query = f'''SELECT project_code, iec_eqpt_code, wt_neighbor_01, power_curve_code\n",
    "    FROM wdm.adm_eqpt_wt \n",
    "    WHERE project_code = '{PROJECT}' ;\n",
    "    '''\n",
    "    \n",
    "    with connexion_setup('SBX-WDM').connect() as conn:\n",
    "        wtg_eqpt_codes = pd.read_sql_query(sql=query, con=conn, params={})\n",
    "    \n",
    "    WTGS = tuple(wtg_eqpt_codes.iec_eqpt_code)\n",
    "        \n",
    "    #10 minutes data extraction\n",
    "    for MONTH in months_list :\n",
    "        FROM_DATE =  MONTH + '-01 00:00:00'  # included\n",
    "        if int(MONTH[-2:])==12:\n",
    "            TO_DATE = f'{int(MONTH[:-3]) + 1}-01-01 00:00:00'      # not included \n",
    "        elif int(MONTH[-2:])>=9:\n",
    "                TO_DATE = f'{MONTH[:-3]}-{int(MONTH[-2:]) + 1}-01 00:00:00'      # not included \n",
    "        else :\n",
    "            TO_DATE = f'{MONTH[:-3]}-0{int(MONTH[-2:]) + 1}-01 00:00:00'      # not included \n",
    "            TO_DATE = f'2021-12-01 00:00:00'      # not included\n",
    "            \n",
    "        DATES = [d.strftime('%Y%m%d') for d in pd.date_range(FROM_DATE, TO_DATE)]\n",
    "        _10min_tables = [f'eu_data.tur_10m_{date}_q' for date in DATES[:-1]]\n",
    "        query = \"\"\n",
    "        \n",
    "        for i, table in enumerate(_10min_tables):\n",
    "            if i != 0:\n",
    "                query = query + \"UNION\\n\"\n",
    "            query = query + f'''SELECT  asset_id, \n",
    "            ts,\n",
    "            {features_selection_str}\n",
    "            FROM {table} WHERE project = '{PROJECT}' AND tech_source = 'PIOEM' \\n'''\n",
    "            \n",
    "        query = query + \"ORDER BY ts ;\"\n",
    "        \n",
    "        with (connexion_setup('PWU-RSH').connect()) as conn:\n",
    "            _10min = pd.read_sql_query(sql=query, con=conn)    # query_red(conn, query)\n",
    "            \n",
    "        _10min.rename(columns=iec2std, inplace=True)\n",
    "        \n",
    "        # re-order columns\n",
    "        col_selection = _10min.columns.sort_values()\n",
    "        _10min = _10min.loc[:,col_selection]\n",
    "        \n",
    "        _10min_project = pd.concat([_10min_project, _10min])\n",
    "        \n",
    "    #On converti le timestamp\n",
    "    _10min_project['year'] = _10min_project.ts.map(lambda date: date.year)\n",
    "    _10min_project['month'] = _10min_project.ts.map(lambda date: date.month)\n",
    "    _10min_project['day'] = _10min_project.ts.map(lambda date: date.day)\n",
    "    _10min_project['hour'] = _10min_project.ts.map(lambda date: date.hour)\n",
    "    _10min_project['minute'] = _10min_project.ts.map(lambda date: date.minute)\n",
    "    \n",
    "    #On récupère le nom de projet et le numéro de turbine\n",
    "    _10min_project['project'] = _10min_project.asset_id.map(lambda name: name[0:4])\n",
    "    _10min_project['turbine'] = _10min_project.asset_id.map(lambda name: int(name[-3:]))\n",
    "    \n",
    "    #On garde les informations utiles\n",
    "    _10min_project.drop(['asset_id','ts'], axis=1, inplace=True)\n",
    "    #On modifie l'index pour retrouver plus facilement les données\n",
    "    _10min_project.set_index(['project','turbine','year','month','day','hour','minute'], inplace=True)\n",
    "\n",
    "    #Sauvegarde sur le notebook\n",
    "    _10min_path = Path('/home/ec2-user/SageMaker/EtudeWindIndex/Data/Windga/WindGa_hourly/Clean/10min_'+PROJECT+'.csv')\n",
    "    _10min_project.to_csv(_10min_path, index=False, sep=';')\n",
    "    \n",
    "    #Sauvegarde sur le S3\n",
    "    outfile = '10min_'+PROJECT+'.csv'\n",
    "    _10min_project.to_csv(f's3://{S3_bucket_name}/{S3_CSV_FOLD}/{outfile}', index=True, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ff6ea",
   "metadata": {},
   "source": [
    "# Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f9a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_era5_folder = r'EtudeWindIndex/ERA5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0126893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2022-01-31 13:34:05,221 -  INFO -  project : CDBO\n",
      " 2022-01-31 13:34:05,222 -  INFO -  Lecture des données era5\n",
      " 2022-01-31 13:34:05,236 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 13:34:05,242 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 13:34:05,244 -  INFO -  We detected language [('English', 0.9545), ('Indonesian', 0.9545), ('Simple English', 0.9545)] using ascii\n",
      " 2022-01-31 13:34:05,245 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 13:34:05,254 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 13:34:05,255 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 13:34:05,256 -  INFO -  We detected language [('German', 0.8333), ('Hungarian', 0.8333), ('Slovak', 0.8333), ('English', 0.75), ('Dutch', 0.75), ('Italian', 0.75), ('Swedish', 0.75), ('Norwegian', 0.75), ('Czech', 0.75), ('Indonesian', 0.75), ('Danish', 0.75), ('Polish', 0.6667), ('Finnish', 0.6667), ('Slovene', 0.6667), ('Turkish', 0.5833), ('Vietnamese', 0.5), ('Lithuanian', 0.5)] using ascii\n",
      " 2022-01-31 13:34:05,257 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 13:34:05,276 -  INFO -  ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      " 2022-01-31 13:34:05,277 -  INFO -  ascii should target any language(s) of ['Latin Based']\n",
      " 2022-01-31 13:34:05,282 -  INFO -  We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      " 2022-01-31 13:34:05,284 -  INFO -  ascii is most likely the one. Stopping the process.\n",
      " 2022-01-31 13:34:07,735 -  INFO -  Lecture des données turbine\n",
      " 2022-01-31 13:34:24,656 -  INFO -  Construction du fichier de comparaison\n",
      " 2022-01-31 13:34:24,694 -  INFO -  année 2020\n",
      " 2022-01-31 13:34:25,045 -  INFO -  8%\n",
      " 2022-01-31 13:35:13,102 -  INFO -  16%\n",
      " 2022-01-31 13:35:58,992 -  INFO -  25%\n",
      " 2022-01-31 13:36:47,089 -  INFO -  33%\n",
      " 2022-01-31 13:37:34,006 -  INFO -  41%\n",
      " 2022-01-31 13:38:22,065 -  INFO -  50%\n",
      " 2022-01-31 13:39:09,444 -  INFO -  58%\n",
      " 2022-01-31 13:39:57,113 -  INFO -  66%\n",
      " 2022-01-31 13:40:45,741 -  INFO -  75%\n",
      " 2022-01-31 13:41:32,980 -  INFO -  83%\n",
      " 2022-01-31 13:42:21,009 -  INFO -  91%\n",
      " 2022-01-31 13:43:07,480 -  INFO -  100%\n",
      " 2022-01-31 13:43:54,731 -  INFO -  année 2021\n",
      " 2022-01-31 13:43:55,267 -  INFO -  9%\n",
      " 2022-01-31 13:44:44,485 -  INFO -  18%\n",
      " 2022-01-31 13:45:28,139 -  INFO -  27%\n",
      " 2022-01-31 13:46:15,863 -  INFO -  36%\n",
      " 2022-01-31 13:47:02,283 -  INFO -  45%\n",
      " 2022-01-31 13:47:51,384 -  INFO -  54%\n",
      " 2022-01-31 13:48:38,590 -  INFO -  63%\n",
      " 2022-01-31 13:49:27,036 -  INFO -  72%\n",
      " 2022-01-31 13:50:15,007 -  INFO -  81%\n",
      " 2022-01-31 13:51:02,846 -  INFO -  90%\n",
      " 2022-01-31 13:51:50,831 -  INFO -  100%\n",
      " 2022-01-31 13:52:37,664 -  INFO -  project : AMEL\n",
      " 2022-01-31 13:52:37,664 -  INFO -  Lecture des données era5\n",
      " 2022-01-31 13:52:40,414 -  INFO -  Lecture des données turbine\n",
      " 2022-01-31 13:52:51,788 -  INFO -  Construction du fichier de comparaison\n",
      " 2022-01-31 13:52:51,815 -  INFO -  année 2020\n",
      " 2022-01-31 13:52:52,068 -  INFO -  8%\n",
      " 2022-01-31 13:53:25,559 -  INFO -  16%\n",
      " 2022-01-31 13:53:56,346 -  INFO -  25%\n",
      " 2022-01-31 13:54:28,840 -  INFO -  33%\n",
      " 2022-01-31 13:55:00,214 -  INFO -  41%\n",
      " 2022-01-31 13:55:33,083 -  INFO -  50%\n",
      " 2022-01-31 13:56:04,340 -  INFO -  58%\n",
      " 2022-01-31 13:56:37,501 -  INFO -  66%\n",
      " 2022-01-31 13:57:09,461 -  INFO -  75%\n",
      " 2022-01-31 13:57:40,535 -  INFO -  83%\n",
      " 2022-01-31 13:58:13,192 -  INFO -  91%\n",
      " 2022-01-31 13:58:44,353 -  INFO -  100%\n",
      " 2022-01-31 13:59:16,474 -  INFO -  année 2021\n",
      " 2022-01-31 13:59:16,820 -  INFO -  9%\n",
      " 2022-01-31 13:59:50,065 -  INFO -  18%\n",
      " 2022-01-31 14:00:20,511 -  INFO -  27%\n",
      " 2022-01-31 14:00:52,746 -  INFO -  36%\n",
      " 2022-01-31 14:01:24,424 -  INFO -  45%\n",
      " 2022-01-31 14:01:56,677 -  INFO -  54%\n",
      " 2022-01-31 14:02:29,451 -  INFO -  63%\n",
      " 2022-01-31 14:03:02,282 -  INFO -  72%\n",
      " 2022-01-31 14:03:34,982 -  INFO -  81%\n",
      " 2022-01-31 14:04:07,076 -  INFO -  90%\n",
      " 2022-01-31 14:04:39,398 -  INFO -  100%\n",
      " 2022-01-31 14:05:10,680 -  INFO -  project : ESPS\n",
      " 2022-01-31 14:05:10,681 -  INFO -  Lecture des données era5\n",
      " 2022-01-31 14:05:13,121 -  INFO -  Lecture des données turbine\n",
      " 2022-01-31 14:05:24,916 -  INFO -  Construction du fichier de comparaison\n",
      " 2022-01-31 14:05:24,952 -  INFO -  année 2020\n",
      " 2022-01-31 14:05:25,151 -  INFO -  8%\n",
      " 2022-01-31 14:05:57,967 -  INFO -  16%\n",
      " 2022-01-31 14:06:27,975 -  INFO -  25%\n",
      " 2022-01-31 14:06:59,748 -  INFO -  33%\n",
      " 2022-01-31 14:07:31,023 -  INFO -  41%\n",
      " 2022-01-31 14:08:03,724 -  INFO -  50%\n",
      " 2022-01-31 14:08:36,557 -  INFO -  58%\n",
      " 2022-01-31 14:09:09,670 -  INFO -  66%\n",
      " 2022-01-31 14:09:41,956 -  INFO -  75%\n",
      " 2022-01-31 14:10:14,703 -  INFO -  83%\n",
      " 2022-01-31 14:10:47,689 -  INFO -  91%\n",
      " 2022-01-31 14:11:19,410 -  INFO -  100%\n",
      " 2022-01-31 14:11:52,966 -  INFO -  année 2021\n",
      " 2022-01-31 14:11:53,293 -  INFO -  9%\n",
      " 2022-01-31 14:12:25,962 -  INFO -  18%\n",
      " 2022-01-31 14:12:55,384 -  INFO -  27%\n",
      " 2022-01-31 14:13:27,904 -  INFO -  36%\n",
      " 2022-01-31 14:13:59,321 -  INFO -  45%\n",
      " 2022-01-31 14:14:33,493 -  INFO -  54%\n",
      " 2022-01-31 14:15:06,037 -  INFO -  63%\n",
      " 2022-01-31 14:15:38,771 -  INFO -  72%\n",
      " 2022-01-31 14:16:11,914 -  INFO -  81%\n",
      " 2022-01-31 14:16:43,648 -  INFO -  90%\n",
      " 2022-01-31 14:17:16,930 -  INFO -  100%\n"
     ]
    }
   ],
   "source": [
    "for project in List_projects :\n",
    "    \n",
    "    logging.info(\"project : {}\".format(project))\n",
    "    \n",
    "    logging.info(\"Lecture des données era5\")\n",
    "    \n",
    "    #Lecture de l'export horraire de ERA5\n",
    "    FILE_ERA5 = 'ERA5_' + project\n",
    "    S3_era5 = f's3://{S3_bucket_name}/{S3_CSV_FOLD_ERA5}/{FILE_ERA5}.csv'\n",
    "    era5 = pd.read_csv(S3_era5, sep=';')\n",
    "    \n",
    "    #On converti le timestamp\n",
    "    era5['year'] = era5.time.map(lambda date: int(date[:4]))\n",
    "    era5['month'] = era5.time.map(lambda date: int(date[5:7]))\n",
    "    era5['day'] = era5.time.map(lambda date: int(date[8:10]))\n",
    "    era5['hour'] = era5.time.map(lambda date: int(date[11:13]))\n",
    "    \n",
    "    #On garde les informations utiles\n",
    "    era5.drop(['time','d2m','t2m','sp','wd100','ws10','wd10','rh','density',\"E100\",'E100_cor'], axis=1, inplace=True)\n",
    "    era5.rename(columns={\"ws100\":\"windspeed_era5\"}, inplace=True)\n",
    "    era5 = era5[['year','month','day','hour','windspeed_era5']]\n",
    "    \n",
    "    logging.info(\"Lecture des données turbine\")\n",
    "    \n",
    "    #Lecture de l'export horraire turbine\n",
    "    FILE_DATA = '10min_' + project\n",
    "    S3_real = f's3://{S3_bucket_name}/{S3_CSV_FOLD_DATA}/{FILE_DATA}.csv'\n",
    "    data = pd.read_csv(S3_real, sep=';')\n",
    "    \n",
    "    logging.info(\"Construction du fichier de comparaison\")\n",
    "    \n",
    "    #Calcul des valeurs horaires *\n",
    "    comp_ws = pd.DataFrame(columns=['year','month','day','hour','windspeed_data','windspeed_era5'])\n",
    "    \n",
    "    for year in data.year.unique().tolist() :\n",
    "        logging.info(\"année \"+str(year))\n",
    "        for month in data[data.year==year].month.unique().tolist() :\n",
    "            logging.info(str(int(month/len(data[data.year==year].month.unique().tolist())*100))+\"%\")\n",
    "            for day in data[(data.year==year)&(data.month==month)].day.unique().tolist() :\n",
    "                for hour in data[(data.year==year)&(data.month==month)&(data.day==day)].hour.unique().tolist() :\n",
    "                    \n",
    "                    mask_data = (data.year==year) & (data.month==month) & (data.day==day) & (data.hour==hour)\n",
    "                    windspeed_data = data.loc[mask_data].wind_speed_avg.unique().mean()\n",
    "                    \n",
    "                    mask_era5 = (era5.year==year) & (era5.month==month) & (era5.day==day) & (era5.hour==hour)\n",
    "                    try :\n",
    "                        windspeed_era5 = float(era5.loc[mask_era5].windspeed_era5)\n",
    "                    except :\n",
    "                        windspeed_era5 = 0\n",
    "                        \n",
    "                    comp_ws = comp_ws.append({'year':year,'month':month,'day':day,'hour':hour,'windspeed_data':windspeed_data,'windspeed_era5':windspeed_era5},ignore_index=True)\n",
    "        \n",
    "    #Sauvegarde sur le notebook\n",
    "    comp_ws_path = Path('/home/ec2-user/SageMaker/EtudeWindIndex/Data/comp_ws_'+project+'.csv')\n",
    "    comp_ws.to_csv(comp_ws_path, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec8f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
